{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:45:11.858023Z",
     "start_time": "2025-10-09T16:45:08.959657Z"
    }
   },
   "source": [
    "import torch\n",
    "from utils import DataManager, dataset_sizes, collect_training_data, compute_statistics, compute_average_accuracies\n",
    "import matplotlib.pyplot as plt\n",
    "from probes import CCSProbe, TTPD, LRProbe, MMProbe, ALL_PROBES, TTPD_TYPES, measure_polarity_direction_lr, train_ttpd_test\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.tune import BasicVariantGenerator"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flohop/miniconda3/envs/truth_is_universal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-09 17:45:11,762\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-10-09 17:45:11,825\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:45:13.067852Z",
     "start_time": "2025-10-09T16:45:13.053343Z"
    }
   },
   "source": [
    "# hyperparameters\n",
    "model_family = 'Llama3' # options are 'Llama3', 'Llama2', 'Gemma', 'Gemma2' or 'Mistral'\n",
    "model_size = '8B'\n",
    "model_type = 'chat' # options are 'chat' or 'base'\n",
    "layer = 12 # layer from which to extract activations\n",
    "\n",
    "device = 'mps' if torch.mps.is_available() else 'cpu' # mps speeds up CCS training a fair bit but is not required\n",
    "device = \"cuda\" if torch.cuda.is_available() else device # cuda speeds it up a bit more\n",
    "device"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:45:14.383943Z",
     "start_time": "2025-10-09T16:45:14.381001Z"
    }
   },
   "source": [
    "# define datasets used for training\n",
    "train_sets = [\"cities\", \"neg_cities\", \"sp_en_trans\", \"neg_sp_en_trans\", \"inventors\", \"neg_inventors\", \"animal_class\",\n",
    "                  \"neg_animal_class\", \"element_symb\", \"neg_element_symb\", \"facts\", \"neg_facts\"]\n",
    "\n",
    "# train_sets = [\"cities\", \"sp_en_trans\", \"inventors\",  \"animal_class\", \"element_symb\", \"facts\"]\n",
    "\n",
    "# get size of each training dataset to include an equal number of statements from each topic in training data\n",
    "train_set_sizes = dataset_sizes(train_sets)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fine Tuner"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:46:49.620407Z",
     "start_time": "2025-10-09T16:46:31.821976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_family = 'Llama3'\n",
    "model_size = '8B'\n",
    "model_type = 'chat'\n",
    "layer = 12\n",
    "device = 'mps' if torch.has_mps else 'cpu'\n",
    "\n",
    "train_sets = [\"cities\", \"neg_cities\", \"sp_en_trans\", \"neg_sp_en_trans\", \"inventors\", \"neg_inventors\",\n",
    "              \"animal_class\", \"neg_animal_class\", \"element_symb\", \"neg_element_symb\", \"facts\", \"neg_facts\"]\n",
    "val_sets = [\"cities_conj\", \"cities_disj\", \"sp_en_trans_conj\", \"sp_en_trans_disj\",\n",
    "            \"inventors_conj\", \"inventors_disj\", \"animal_class_conj\", \"animal_class_disj\",\n",
    "            \"element_symb_conj\", \"element_symb_disj\", \"facts_conj\", \"facts_disj\",\n",
    "            \"common_claim_true_false\", \"counterfact_true_false\"]\n",
    "\n",
    "train_set_sizes = dataset_sizes(train_sets)\n",
    "val_set_sizes = dataset_sizes(val_sets)\n",
    "\n",
    "acts_centered_train, acts_train, labels_train, polarities_train = collect_training_data(\n",
    "    train_sets, train_set_sizes, model_family, model_size, model_type, layer\n",
    ")\n",
    "acts_centered_val, acts_val, labels_val, polarities_val = collect_training_data(\n",
    "    val_sets, val_set_sizes, model_family, model_size, model_type, layer\n",
    ")\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "search_space = {\n",
    "    'C': tune.loguniform(1e-3, 10),\n",
    "    'fit_intercept': tune.choice([True, False]),\n",
    "    'solver': tune.choice(['lbfgs', 'saga', 'liblinear']),\n",
    "    'degree': tune.choice([1,2,3]),\n",
    "    'include_bias': tune.choice([True, False]),\n",
    "    'use_scaler': tune.choice([True, False]),\n",
    "    'interaction_features': tune.choice([\n",
    "        ['proj_t_g', 'proj_t_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'inter1'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_t_g+proj_t_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_t_g-proj_t_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_t_g*proj_t_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_p', 'proj_t_g*proj_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_p', 'proj_t_p*proj_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_p', 'proj_t_g*proj_t_p*proj_p'],\n",
    "        ['proj_t_g', 'proj_t_p', 'proj_p', 'inter1'],\n",
    "    ])\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(\n",
    "        train_ttpd_test,\n",
    "        acts_centered_train=acts_centered_train,\n",
    "        acts_train=acts_train,\n",
    "        labels_train=labels_train,\n",
    "        polarities_train=polarities_train,\n",
    "        acts_centered_val=acts_centered_val,\n",
    "        acts_val=acts_val,\n",
    "        labels_val=labels_val,\n",
    "        polarities_val=polarities_val\n",
    "    ),\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    "    num_samples=20,\n",
    "    config=search_space\n",
    ")\n",
    "print(\"Best acc: \", analysis.best_result[\"accuracy\"])\n",
    "print(\"Best config found:\", analysis.best_config)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mq/hzv322c546j2vlkdh07ydd4w0000gn/T/ipykernel_14590/3216064882.py:5: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = 'mps' if torch.has_mps else 'cpu'\n",
      "2025-10-09 17:46:31,892\tINFO worker.py:1789 -- Calling ray.init() again after it has already been called.\n",
      "2025-10-09 17:46:31,900\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-10-09 17:46:31,902\tWARNING callback.py:143 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-09 17:46:32</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.19        </td></tr>\n",
       "<tr><td>Memory:      </td><td>16.6/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 12.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         C</th><th style=\"text-align: right;\">  degree</th><th>fit_intercept  </th><th>include_bias  </th><th>interaction_features  </th><th>solver   </th><th>use_scaler  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_ttpd_test_8271c_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">4.05735   </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8500  </td><td>liblinear</td><td>True        </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">4.63788   </td><td style=\"text-align: right;\">       2</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_d500  </td><td>saga     </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">2.47164   </td><td style=\"text-align: right;\">       1</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8880  </td><td>saga     </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0705936 </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_ba80  </td><td>lbfgs    </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00164352</td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_a980  </td><td>lbfgs    </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.289404  </td><td style=\"text-align: right;\">       3</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_9d00  </td><td>liblinear</td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">3.02887   </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_b140  </td><td>liblinear</td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.185462  </td><td style=\"text-align: right;\">       2</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8c40  </td><td>saga     </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00622612</td><td style=\"text-align: right;\">       1</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_1b80  </td><td>liblinear</td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.73117   </td><td style=\"text-align: right;\">       3</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_a640  </td><td>liblinear</td><td>True        </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00234122</td><td style=\"text-align: right;\">       3</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_9e40  </td><td>saga     </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.023238  </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8440  </td><td>saga     </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">2.5829    </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_b4c0  </td><td>liblinear</td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00183031</td><td style=\"text-align: right;\">       2</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_3380  </td><td>saga     </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.738354  </td><td style=\"text-align: right;\">       2</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_08c0  </td><td>liblinear</td><td>True        </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0167304 </td><td style=\"text-align: right;\">       1</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_4cc0  </td><td>liblinear</td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.322167  </td><td style=\"text-align: right;\">       1</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_0800  </td><td>liblinear</td><td>True        </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00634427</td><td style=\"text-align: right;\">       1</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8a40  </td><td>liblinear</td><td>True        </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00188099</td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8700  </td><td>saga     </td><td>False       </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0108538 </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_abc0  </td><td>saga     </td><td>False       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-09 17:46:49</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:17.70        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.0/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 2.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">         C</th><th style=\"text-align: right;\">  degree</th><th>fit_intercept  </th><th>include_bias  </th><th>interaction_features  </th><th>solver   </th><th>use_scaler  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_ttpd_test_8271c_00000</td><td>TERMINATED</td><td>127.0.0.1:14722</td><td style=\"text-align: right;\">4.05735   </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8500  </td><td>liblinear</td><td>True        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0290639</td><td style=\"text-align: right;\">  0.725714</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00001</td><td>TERMINATED</td><td>127.0.0.1:14725</td><td style=\"text-align: right;\">4.63788   </td><td style=\"text-align: right;\">       2</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_d500  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.04842  </td><td style=\"text-align: right;\">  0.754286</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00002</td><td>TERMINATED</td><td>127.0.0.1:14724</td><td style=\"text-align: right;\">2.47164   </td><td style=\"text-align: right;\">       1</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8880  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.02583  </td><td style=\"text-align: right;\">  0.742857</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00003</td><td>TERMINATED</td><td>127.0.0.1:14723</td><td style=\"text-align: right;\">0.0705936 </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_ba80  </td><td>lbfgs    </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0296669</td><td style=\"text-align: right;\">  0.631429</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00004</td><td>TERMINATED</td><td>127.0.0.1:14721</td><td style=\"text-align: right;\">0.00164352</td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_a980  </td><td>lbfgs    </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0401239</td><td style=\"text-align: right;\">  0.688571</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00005</td><td>TERMINATED</td><td>127.0.0.1:14726</td><td style=\"text-align: right;\">0.289404  </td><td style=\"text-align: right;\">       3</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_9d00  </td><td>liblinear</td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0305469</td><td style=\"text-align: right;\">  0.745714</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00006</td><td>TERMINATED</td><td>127.0.0.1:14735</td><td style=\"text-align: right;\">3.02887   </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_b140  </td><td>liblinear</td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.024874 </td><td style=\"text-align: right;\">  0.334286</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00007</td><td>TERMINATED</td><td>127.0.0.1:14737</td><td style=\"text-align: right;\">0.185462  </td><td style=\"text-align: right;\">       2</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8c40  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.024925 </td><td style=\"text-align: right;\">  0.722857</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00008</td><td>TERMINATED</td><td>127.0.0.1:14738</td><td style=\"text-align: right;\">0.00622612</td><td style=\"text-align: right;\">       1</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_1b80  </td><td>liblinear</td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0264211</td><td style=\"text-align: right;\">  0.642857</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00009</td><td>TERMINATED</td><td>127.0.0.1:14740</td><td style=\"text-align: right;\">0.73117   </td><td style=\"text-align: right;\">       3</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_a640  </td><td>liblinear</td><td>True        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0244069</td><td style=\"text-align: right;\">  0.562857</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00010</td><td>TERMINATED</td><td>127.0.0.1:14736</td><td style=\"text-align: right;\">0.00234122</td><td style=\"text-align: right;\">       3</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_9e40  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0613592</td><td style=\"text-align: right;\">  0.488571</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00011</td><td>TERMINATED</td><td>127.0.0.1:14739</td><td style=\"text-align: right;\">0.023238  </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8440  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0503232</td><td style=\"text-align: right;\">  0.482857</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00012</td><td>TERMINATED</td><td>127.0.0.1:14748</td><td style=\"text-align: right;\">2.5829    </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_b4c0  </td><td>liblinear</td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0271771</td><td style=\"text-align: right;\">  0.688571</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00013</td><td>TERMINATED</td><td>127.0.0.1:14747</td><td style=\"text-align: right;\">0.00183031</td><td style=\"text-align: right;\">       2</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_3380  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0337472</td><td style=\"text-align: right;\">  0.594286</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00014</td><td>TERMINATED</td><td>127.0.0.1:14750</td><td style=\"text-align: right;\">0.738354  </td><td style=\"text-align: right;\">       2</td><td>True           </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_08c0  </td><td>liblinear</td><td>True        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0321741</td><td style=\"text-align: right;\">  0.457143</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00015</td><td>TERMINATED</td><td>127.0.0.1:14752</td><td style=\"text-align: right;\">0.0167304 </td><td style=\"text-align: right;\">       1</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_4cc0  </td><td>liblinear</td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0318339</td><td style=\"text-align: right;\">  0.748571</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00016</td><td>TERMINATED</td><td>127.0.0.1:14749</td><td style=\"text-align: right;\">0.322167  </td><td style=\"text-align: right;\">       1</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_0800  </td><td>liblinear</td><td>True        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0357277</td><td style=\"text-align: right;\">  0.745714</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00017</td><td>TERMINATED</td><td>127.0.0.1:14751</td><td style=\"text-align: right;\">0.00634427</td><td style=\"text-align: right;\">       1</td><td>True           </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8a40  </td><td>liblinear</td><td>True        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0563071</td><td style=\"text-align: right;\">  0.625714</td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00018</td><td>TERMINATED</td><td>127.0.0.1:14763</td><td style=\"text-align: right;\">0.00188099</td><td style=\"text-align: right;\">       2</td><td>False          </td><td>True          </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_8700  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0227799</td><td style=\"text-align: right;\">  0.56    </td></tr>\n",
       "<tr><td>train_ttpd_test_8271c_00019</td><td>TERMINATED</td><td>127.0.0.1:14764</td><td style=\"text-align: right;\">0.0108538 </td><td style=\"text-align: right;\">       2</td><td>False          </td><td>False         </td><td>[&#x27;proj_t_g&#x27;, &#x27;p_abc0  </td><td>saga     </td><td>False       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0207772</td><td style=\"text-align: right;\">  0.717143</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 17:46:49,606\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/flohop/ray_results/train_ttpd_test_2025-10-09_17-46-31' in 0.0146s.\n",
      "2025-10-09 17:46:49,609\tINFO tune.py:1041 -- Total run time: 17.71 seconds (17.69 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best acc:  0.7542857142857143\n",
      "Best config found: {'C': 4.637881213249649, 'fit_intercept': True, 'solver': 'saga', 'degree': 2, 'include_bias': True, 'use_scaler': False, 'interaction_features': ['proj_t_g', 'proj_t_p', 'proj_t_g+proj_t_p']}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Polarity direction accuracy"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_sets = [\"cities_conj\", \"cities_disj\", \"sp_en_trans_conj\", \"sp_en_trans_disj\",\n",
    "                \"inventors_conj\", \"inventors_disj\", \"animal_class_conj\", \"animal_class_disj\",\n",
    "                \"element_symb_conj\", \"element_symb_disj\", \"facts_conj\", \"facts_disj\",\n",
    "                \"common_claim_true_false\", \"counterfact_true_false\"]\n",
    "\n",
    "val_set_sizes = dataset_sizes(val_sets)\n",
    "\n",
    "cv_train_sets = np.array(train_sets)\n",
    "cv_test_sets = np.array(val_sets)\n",
    "acts_centered, acts, labels, polarities = collect_training_data(cv_train_sets, train_set_sizes, model_family,\n",
    "                                                                    model_size, model_type, layer)\n",
    "\n",
    "# Test set\n",
    "t_acts_centered, t_acts, t_labels, t_polarities = collect_training_data(cv_test_sets, dataset_sizes(val_sets), model_family, model_size, model_type, layer)\n",
    "\n",
    "measure_polarity_direction_lr(acts, polarities, t_acts, t_polarities)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Unseen topics"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# compare TTPD, LR and CCS on topic-specific datasets\n",
    "probe_types = [t for (name, t) in ALL_PROBES]\n",
    "results = {t: defaultdict(list) for t in probe_types}\n",
    "num_iter = 3\n",
    "\n",
    "TTPD_CLASSES = [v for (k, v) in TTPD_TYPES]\n",
    "\n",
    "total_iterations = len(probe_types) * num_iter * len(train_sets)\n",
    "with tqdm(total=total_iterations, desc=\"Training and evaluating classifiers\") as pbar: # progress bar\n",
    "    for probe_type in probe_types:\n",
    "        for n in range(num_iter):\n",
    "            indices = np.arange(0, 12, 2)\n",
    "            for i in indices:\n",
    "                cv_train_sets = np.delete(np.array(train_sets), [i, i+1], axis=0)\n",
    "                # load training data\n",
    "                acts_centered, acts, labels, polarities = collect_training_data(cv_train_sets, train_set_sizes, model_family,\n",
    "                                                                                model_size, model_type, layer)\n",
    "\n",
    "                if probe_type in TTPD_CLASSES:\n",
    "                    probe = probe_type.from_data(acts_centered, acts, labels, polarities)\n",
    "                elif probe_type == LRProbe:\n",
    "                    probe = LRProbe.from_data(acts, labels)\n",
    "                elif probe_type == CCSProbe:\n",
    "                    acts_affirm = acts[polarities == 1.0]\n",
    "                    acts_neg = acts[polarities == -1.0]\n",
    "                    labels_affirm = labels[polarities == 1.0]\n",
    "                    mean_affirm = torch.mean(acts_affirm, dim=0)\n",
    "                    mean_neg = torch.mean(acts_neg, dim=0)\n",
    "                    acts_affirm = acts_affirm - mean_affirm\n",
    "                    acts_neg = acts_neg - mean_neg\n",
    "                    probe = CCSProbe.from_data(acts_affirm, acts_neg, labels_affirm, device=device).to('cpu')\n",
    "                elif probe_type == MMProbe:\n",
    "                    probe = MMProbe.from_data(acts, labels)\n",
    "\n",
    "                # evaluate classification accuracy on held out datasets\n",
    "                dm = DataManager()\n",
    "                for j in range(0,2):\n",
    "                    dm.add_dataset(train_sets[i+j], model_family, model_size, model_type, layer, split=None, center=False, device='cpu')\n",
    "                    acts, labels = dm.data[train_sets[i+j]]\n",
    "\n",
    "                    # classifier specific predictions\n",
    "                    if probe_type == CCSProbe:\n",
    "                        if j == 0:\n",
    "                            acts = acts - mean_affirm\n",
    "                        if j == 1:\n",
    "                            acts = acts - mean_neg\n",
    "                    predictions = probe.pred(acts)\n",
    "                    results[probe_type][train_sets[i+j]].append((predictions == labels).float().mean().item())\n",
    "                    pbar.update(1)\n",
    "\n",
    "stat_results = compute_statistics(results)\n",
    "\n",
    "# Compute mean accuracies and standard deviations for each probe type\n",
    "probe_accuracies = compute_average_accuracies(results, num_iter)\n",
    "\n",
    "for probe_type, stats in probe_accuracies.items():\n",
    "    print(f\"{probe_type}:\")\n",
    "    print(f\"  Mean Accuracy: {stats['mean']*100:.2f}%\")\n",
    "    print(f\"  Standard Deviation of the mean accuracy: {stats['std_dev']*100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "probes = [p for (t, p ) in ALL_PROBES]\n",
    "titles = [t for (t, p) in ALL_PROBES]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(14, 6), ncols=len(probes))\n",
    "\n",
    "if len(probes) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "\n",
    "for t, (ax, key) in enumerate(zip(axes, probes)):\n",
    "    grid = [[stat_results[key]['mean'][dataset]] for dataset in train_sets]\n",
    "    grid_std = [[stat_results[key]['std'][dataset]] for dataset in train_sets]\n",
    "\n",
    "    im = ax.imshow(grid, vmin=0, vmax=1, cmap='plasma', aspect='auto')\n",
    "\n",
    "    for i, row in enumerate(grid):\n",
    "        for j, val in enumerate(row):\n",
    "            ax.text(j, i, f'{round(grid[i][j] * 100):2d} $\\pm$ {round(grid_std[i][j] * 100):2d}',\n",
    "                    ha='center', va='center', fontsize=13)\n",
    "\n",
    "    ax.set_yticks(range(len(train_sets)))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(titles[t], fontsize=12)\n",
    "\n",
    "# y tick labels only on first subplot\n",
    "axes[0].set_yticklabels(train_sets, fontsize=12)\n",
    "for ax in axes[1:]:\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axes, shrink=0.6, location=\"right\")\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "fig.suptitle(\"Classification accuracies\", fontsize=15)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalisation to logical conjunctions and disjunctions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# compare TTPD, LR, CCS and MM on logical conjunctions and disjunctions\n",
    "val_sets = [\"cities_conj\", \"cities_disj\", \"sp_en_trans_conj\",\"sp_en_trans_disj\",\n",
    "             \"inventors_conj\", \"inventors_disj\", \"animal_class_conj\", \"animal_class_disj\",\n",
    "               \"element_symb_conj\", \"element_symb_disj\", \"facts_conj\", \"facts_disj\",\n",
    "            \"common_claim_true_false\", \"counterfact_true_false\"]\n",
    "\n",
    "\n",
    "probe_types = [t for (name, t) in ALL_PROBES]\n",
    "results = {t: defaultdict(list) for t in probe_types}\n",
    "\n",
    "TTPD_CLASSES = [v for (k, v) in TTPD_TYPES]\n",
    "\n",
    "\n",
    "num_iter = 20\n",
    "\n",
    "total_iterations = len(probe_types) * num_iter\n",
    "with tqdm(total=total_iterations, desc=\"Training and evaluating classifiers\") as pbar: # progress bar\n",
    "    for probe_type in probe_types:\n",
    "        for n in range(num_iter):\n",
    "            # load training data\n",
    "            acts_centered, acts, labels, polarities = collect_training_data(train_sets, train_set_sizes, model_family, model_size,\n",
    "                                                                             model_type, layer)\n",
    "\n",
    "            if probe_type in TTPD_CLASSES:\n",
    "                probe = probe_type.from_data(acts_centered, acts, labels, polarities)\n",
    "            if probe_type == LRProbe:\n",
    "                probe = LRProbe.from_data(acts, labels)\n",
    "            if probe_type == CCSProbe:\n",
    "                acts_affirm = acts[polarities == 1.0]\n",
    "                acts_neg = acts[polarities == -1.0]\n",
    "                labels_affirm = labels[polarities == 1.0]\n",
    "                mean_affirm = torch.mean(acts_affirm, dim=0) \n",
    "                mean_neg = torch.mean(acts_neg, dim=0)\n",
    "                acts_affirm = acts_affirm - mean_affirm\n",
    "                acts_neg = acts_neg - mean_neg\n",
    "                probe = CCSProbe.from_data(acts_affirm, acts_neg, labels_affirm, device=device).to('cpu')\n",
    "            if probe_type == MMProbe:\n",
    "                probe = MMProbe.from_data(acts, labels)\n",
    "\n",
    "            # evaluate classification accuracy on validation datasets\n",
    "            dm = DataManager()\n",
    "            for val_set in val_sets:\n",
    "                dm.add_dataset(val_set, model_family, model_size, model_type, layer, split=None, center=False, device='cpu')\n",
    "                acts, labels = dm.data[val_set] # retrieve the activations and labels that were just added to the DM\n",
    "                \n",
    "                # classifier specific predictions\n",
    "                if probe_type == CCSProbe:\n",
    "                    acts = acts - (mean_affirm + mean_neg)/2\n",
    "                predictions = probe.pred(acts) # one prediction per example. 0 if we think its a lie, 1 if we predicte its true\n",
    "\n",
    "                # compare prediction with ground truth labels and average it\n",
    "                results[probe_type][val_set].append((predictions == labels).float().mean().item())\n",
    "            pbar.update(1)\n",
    "\n",
    "stat_results = compute_statistics(results)\n",
    "\n",
    "# Compute mean accuracies and standard deviations for each probe type\n",
    "probe_accuracies = compute_average_accuracies(results, num_iter)\n",
    "\n",
    "for probe_type, stats in probe_accuracies.items():\n",
    "    print(f\"{probe_type}:\")\n",
    "    print(f\"  Mean Accuracy: {stats['mean']*100:.2f}%\")\n",
    "    print(f\"  Standard Deviation of the mean accuracy: {stats['std_dev']*100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "probes = [p for (t, p ) in ALL_PROBES]\n",
    "titles = [t for (t, p) in ALL_PROBES]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(14, 6), ncols=len(probes))\n",
    "\n",
    "if len(probes) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "\n",
    "for t, (ax, key) in enumerate(zip(axes, probes)):\n",
    "    grid = [[stat_results[key]['mean'][dataset]] for dataset in val_sets]\n",
    "    grid_std = [[stat_results[key]['std'][dataset]] for dataset in val_sets]\n",
    "\n",
    "    im = ax.imshow(grid, vmin=0, vmax=1, cmap='plasma', aspect='auto')\n",
    "\n",
    "    for i, row in enumerate(grid):\n",
    "        for j, val in enumerate(row):\n",
    "            ax.text(j, i, f'{round(grid[i][j] * 100):2d} $\\pm$ {round(grid_std[i][j] * 100):2d}',\n",
    "                    ha='center', va='center', fontsize=13)\n",
    "\n",
    "    ax.set_yticks(range(len(val_sets)))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(titles[t], fontsize=12)\n",
    "\n",
    "# y tick labels only on first subplot\n",
    "axes[0].set_yticklabels(val_sets, fontsize=12)\n",
    "for ax in axes[1:]:\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axes, shrink=0.6, location='right')\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "fig.suptitle(\"Classification accuracies\", fontsize=15)\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalisation to German statements"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# compare TTPD, LR, CCS and MM on statements translated to german\n",
    "val_sets = [\"cities_de\", \"neg_cities_de\", \"sp_en_trans_de\", \"neg_sp_en_trans_de\", \"inventors_de\", \"neg_inventors_de\", \"animal_class_de\",\n",
    "                  \"neg_animal_class_de\", \"element_symb_de\", \"neg_element_symb_de\", \"facts_de\", \"neg_facts_de\"]\n",
    "\n",
    "probe_types = [t for (name, t) in ALL_PROBES]\n",
    "results = {t: defaultdict(list) for t in probe_types}\n",
    "\n",
    "num_iter = 20\n",
    "\n",
    "total_iterations = len(probe_types) * num_iter\n",
    "with tqdm(total=total_iterations, desc=\"Training and evaluating classifiers\") as pbar: # progress bar\n",
    "    for probe_type in probe_types:\n",
    "        for n in range(num_iter):\n",
    "            # load training data\n",
    "            acts_centered, acts, labels, polarities = collect_training_data(train_sets, train_set_sizes, model_family, model_size,\n",
    "                                                                                           model_type, layer)\n",
    "            if probe_type in TTPD_CLASSES:\n",
    "                probe = probe_type.from_data(acts_centered, acts, labels, polarities)\n",
    "            if probe_type == LRProbe:\n",
    "                probe = LRProbe.from_data(acts, labels)\n",
    "            if probe_type == CCSProbe:\n",
    "                acts_affirm = acts[polarities == 1.0]\n",
    "                acts_neg = acts[polarities == -1.0]\n",
    "                labels_affirm = labels[polarities == 1.0]\n",
    "                mean_affirm = torch.mean(acts_affirm, dim=0) \n",
    "                mean_neg = torch.mean(acts_neg, dim=0)\n",
    "                acts_affirm = acts_affirm - mean_affirm\n",
    "                acts_neg = acts_neg - mean_neg\n",
    "                probe = CCSProbe.from_data(acts_affirm, acts_neg, labels_affirm, device=device).to('cpu')\n",
    "            if probe_type == MMProbe:\n",
    "                probe = MMProbe.from_data(acts, labels)\n",
    "\n",
    "            # evaluate classification accuracy on validation datasets\n",
    "            dm = DataManager()\n",
    "            for val_set in val_sets:\n",
    "                dm.add_dataset(val_set, model_family, model_size, model_type, layer, split=None, center=False, device='cpu')\n",
    "                acts, labels = dm.data[val_set]\n",
    "                \n",
    "                # classifier specific predictions\n",
    "                if probe_type == CCSProbe:\n",
    "                    acts = acts - (mean_affirm + mean_neg)/2\n",
    "                predictions = probe.pred(acts)\n",
    "                \n",
    "                results[probe_type][val_set].append((predictions == labels).float().mean().item())\n",
    "            pbar.update(1)\n",
    "\n",
    "stat_results = compute_statistics(results)\n",
    "\n",
    "# Compute mean accuracies and standard deviations for each probe type\n",
    "probe_accuracies = compute_average_accuracies(results, num_iter)\n",
    "\n",
    "for probe_type, stats in probe_accuracies.items():\n",
    "    print(f\"{probe_type}:\")\n",
    "    print(f\"  Mean Accuracy: {stats['mean']*100:.2f}%\")\n",
    "    print(f\"  Standard Deviation of the mean accuracy: {stats['std_dev']*100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "probes = [p for (t, p ) in ALL_PROBES]\n",
    "titles = [t for (t, p) in ALL_PROBES]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(14, 6), ncols=len(probes))\n",
    "\n",
    "\n",
    "if len(probes) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for t, (ax, key) in enumerate(zip(axes, probes)):\n",
    "    grid = [[stat_results[key]['mean'][dataset]] for dataset in val_sets]\n",
    "    grid_std = [[stat_results[key]['std'][dataset]] for dataset in val_sets]\n",
    "\n",
    "    im = ax.imshow(grid, vmin=0, vmax=1, cmap='plasma', aspect='auto')\n",
    "\n",
    "    for i, row in enumerate(grid):\n",
    "        for j, val in enumerate(row):\n",
    "            ax.text(j, i, f'{round(grid[i][j] * 100):2d} $\\pm$ {round(grid_std[i][j] * 100):2d}',\n",
    "                    ha='center', va='center', fontsize=13)\n",
    "\n",
    "    ax.set_yticks(range(len(val_sets)))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(titles[t], fontsize=12)\n",
    "\n",
    "# y tick labels only on first subplot\n",
    "axes[0].set_yticklabels(val_sets, fontsize=12)\n",
    "for ax in axes[1:]:\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "cbar = fig.colorbar(im, ax=axes, shrink=0.6, location='right')\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "fig.suptitle(\"Classification accuracies\", fontsize=15)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying generalisation to Conjunctions, Disjunctions and German statements in one table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the validation sets and the probe types\n",
    "val_sets = [\"cities_conj\", \"cities_disj\", \"sp_en_trans_conj\",\"sp_en_trans_disj\",\n",
    "             \"inventors_conj\", \"inventors_disj\", \"animal_class_conj\", \"animal_class_disj\",\n",
    "               \"element_symb_conj\", \"element_symb_disj\", \"facts_conj\", \"facts_disj\", \"cities_de\", \"neg_cities_de\", \"sp_en_trans_de\", \"neg_sp_en_trans_de\", \"inventors_de\", \"neg_inventors_de\", \"animal_class_de\",\n",
    "                  \"neg_animal_class_de\", \"element_symb_de\", \"neg_element_symb_de\", \"facts_de\", \"neg_facts_de\",\n",
    "            \"common_claim_true_false\", \"counterfact_true_false\"]\n",
    "\n",
    "probe_types = [t for (name, t) in ALL_PROBES]\n",
    "results = {t: defaultdict(list) for t in probe_types}\n",
    "num_iter = 20\n",
    "\n",
    "TTPD_CLASSES = [v for (k, v) in TTPD_TYPES]\n",
    "\n",
    "# Training and evaluating classifiers\n",
    "total_iterations = len(probe_types) * num_iter\n",
    "with tqdm(total=total_iterations, desc=\"Training and evaluating classifiers\") as pbar:\n",
    "    for probe_type in probe_types:\n",
    "        for n in range(num_iter):\n",
    "            # load training data\n",
    "            acts_centered, acts, labels, polarities = collect_training_data(train_sets, train_set_sizes, model_family, model_size,\n",
    "                                                                                           model_type, layer)\n",
    "            if probe_type in TTPD_CLASSES:\n",
    "                probe = probe_type.from_data(acts_centered, acts, labels, polarities)\n",
    "            if probe_type == LRProbe:\n",
    "                probe = LRProbe.from_data(acts, labels)\n",
    "            if probe_type == CCSProbe:\n",
    "                acts_affirm = acts[polarities == 1.0]\n",
    "                acts_neg = acts[polarities == -1.0]\n",
    "                labels_affirm = labels[polarities == 1.0]\n",
    "                mean_affirm = torch.mean(acts_affirm, dim=0) \n",
    "                mean_neg = torch.mean(acts_neg, dim=0)\n",
    "                acts_affirm = acts_affirm - mean_affirm\n",
    "                acts_neg = acts_neg - mean_neg\n",
    "                probe = CCSProbe.from_data(acts_affirm, acts_neg, labels_affirm, device=device).to('cpu')\n",
    "            if probe_type == MMProbe:\n",
    "                probe = MMProbe.from_data(acts, labels)\n",
    "\n",
    "            # evaluate classification accuracy on validation datasets\n",
    "            dm = DataManager()\n",
    "            for val_set in val_sets:\n",
    "                dm.add_dataset(val_set, model_family, model_size, model_type, layer, split=None, center=False, device='cpu')\n",
    "                acts, labels = dm.data[val_set]\n",
    "                \n",
    "                # classifier specific predictions\n",
    "                if probe_type == CCSProbe:\n",
    "                    acts = acts - (mean_affirm + mean_neg)/2\n",
    "                predictions = probe.pred(acts)\n",
    "                results[probe_type][val_set].append((predictions == labels).float().mean().item())\n",
    "            pbar.update(1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the groups\n",
    "groups = {\n",
    "    'Conjunctions': [dataset for dataset in val_sets if dataset.endswith('_conj')],\n",
    "    'Disjunctions': [dataset for dataset in val_sets if dataset.endswith('_disj')],\n",
    "    'Affirmative German': [dataset for dataset in val_sets if dataset.endswith('_de') and not dataset.startswith('neg_')],\n",
    "    'Negated German': [dataset for dataset in val_sets if dataset.startswith('neg_') and dataset.endswith('_de')],\n",
    "    'common_claim_true_false': ['common_claim_true_false'],\n",
    "    'counterfact_true_false': ['counterfact_true_false']\n",
    "}\n",
    "\n",
    "# Initialize group results\n",
    "group_results = {probe_type: {group_name: [] for group_name in groups} for probe_type in probe_types}\n",
    "\n",
    "# Process results to compute mean accuracies per group per classifier\n",
    "for probe_type in probe_types:\n",
    "    for n in range(num_iter):\n",
    "        for group_name, group_datasets in groups.items():\n",
    "            accuracies = []\n",
    "            for dataset in group_datasets:\n",
    "                accuracy = results[probe_type][dataset][n]\n",
    "                accuracies.append(accuracy)\n",
    "            mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "            group_results[probe_type][group_name].append(mean_accuracy)\n",
    "\n",
    "# Compute statistics\n",
    "stat_group_results = {probe_type: {'mean': {}, 'std': {}} for probe_type in probe_types}\n",
    "\n",
    "for probe_type in probe_types:\n",
    "    for group_name in groups:\n",
    "        accuracies = group_results[probe_type][group_name]\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        stat_group_results[probe_type]['mean'][group_name] = mean_accuracy\n",
    "        stat_group_results[probe_type]['std'][group_name] = std_accuracy\n",
    "\n",
    "# Map probe types to classifier names\n",
    "\n",
    "probe_type_to_name = {probe:name for (name, probe) in ALL_PROBES}\n",
    "\n",
    "# probe_type_to_name = {\n",
    "#     TTPD: 'TTPD',\n",
    "#     TTPD4d: \"TTPD4d\",\n",
    "#     TTPD3dTp: \"TTPD3dTp\",\n",
    "#     TTPD3dTpInv: \"TTPD3dTpInv\",\n",
    "#     LRProbe: 'LR',\n",
    "#     CCSProbe: 'CCS',\n",
    "#     MMProbe: 'MM'\n",
    "# }\n",
    "\n",
    "# Create DataFrames for mean accuracies and standard deviations\n",
    "group_names = ['Conjunctions', 'Disjunctions', 'Affirmative German', 'Negated German', 'common_claim_true_false', 'counterfact_true_false']\n",
    "classifier_names = [n for (n, _) in ALL_PROBES]\n",
    "# classifier_names = ['TTPD', \"TTPD4d\", \"TTPD3dTp\", \"TTPD3dTpInv\", 'LR', 'CCS', 'MM']\n",
    "\n",
    "mean_df = pd.DataFrame(index=group_names, columns=classifier_names)\n",
    "std_df = pd.DataFrame(index=group_names, columns=classifier_names)\n",
    "\n",
    "for probe_type in probe_types:\n",
    "    classifier_name = probe_type_to_name[probe_type]\n",
    "    for group_name in group_names:\n",
    "        mean_accuracy = stat_group_results[probe_type]['mean'][group_name]\n",
    "        std_accuracy = stat_group_results[probe_type]['std'][group_name]\n",
    "        mean_df.loc[group_name, classifier_name] = mean_accuracy\n",
    "        std_df.loc[group_name, classifier_name] = std_accuracy\n",
    "\n",
    "num_classifiers = len(classifier_names)\n",
    "fig, axes = plt.subplots(figsize=(2.5*num_classifiers, 6), ncols=num_classifiers)\n",
    "\n",
    "for idx, classifier_name in enumerate(classifier_names):\n",
    "    ax = axes[idx]\n",
    "    mean_values = mean_df[classifier_name].values.astype(float)\n",
    "    std_values = std_df[classifier_name].values.astype(float)\n",
    "\n",
    "    # Create heatmap with a single column\n",
    "    im = ax.imshow(mean_values[:, np.newaxis], vmin=0, vmax=1, cmap='plasma', aspect='auto')\n",
    "\n",
    "    # Annotate the heatmap\n",
    "    for i in range(len(group_names)):\n",
    "        mean_accuracy = mean_values[i]\n",
    "        std_accuracy = std_values[i]\n",
    "        ax.text(0, i, f'{round(mean_accuracy * 100):2d} ± {round(std_accuracy * 100):2d}',\n",
    "                ha='center', va='center', fontsize=14)\n",
    "\n",
    "    # Set ticks and labels\n",
    "    ax.set_xticks([])\n",
    "    if idx == 0:\n",
    "        ax.set_yticks(np.arange(len(group_names)))\n",
    "        ax.set_yticklabels(group_names, fontsize=14)\n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "    ax.set_title(classifier_name, fontsize=15)\n",
    "\n",
    "# Add colorbar on the right\n",
    "cbar = fig.colorbar(im, ax=axes.ravel().tolist(), location='right', shrink=0.8)\n",
    "cbar.ax.tick_params(labelsize=13)\n",
    "\n",
    "fig.suptitle(\"Classification Accuracies\", fontsize=17)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real world scenarios / lies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "probe_types = [t for (name, t) in ALL_PROBES]\n",
    "results = {t: [] for t in probe_types}\n",
    "num_iter = 50\n",
    "\n",
    "total_iterations = len(probe_types) * num_iter\n",
    "with tqdm(total=total_iterations, desc=\"Training and evaluating classifiers\") as pbar: # progress bar\n",
    "    for probe_type in probe_types:\n",
    "        for n in range(num_iter):\n",
    "            # load training data\n",
    "            acts_centered, acts, labels, polarities = collect_training_data(train_sets, train_set_sizes, model_family,\n",
    "                                                                                           model_size, model_type,layer)\n",
    "            if probe_type == TTPD:\n",
    "                probe = TTPD.from_data(acts_centered, acts, labels, polarities)\n",
    "            if probe_type == TTPD4d:\n",
    "                probe = TTPD4d.from_data(acts_centered, acts, labels, polarities)\n",
    "            if probe_type == TTPD3dTp:\n",
    "                probe = TTPD3dTp.from_data(acts_centered, acts, labels, polarities)\n",
    "            if probe_type == TTPD3dTpInv:\n",
    "                probe = TTPD3dTpInv.from_data(acts_centered, acts, labels, polarities)\n",
    "            if probe_type == LRProbe:\n",
    "                probe = LRProbe.from_data(acts, labels)\n",
    "            if probe_type == CCSProbe:\n",
    "                acts_affirm = acts[polarities == 1.0]\n",
    "                acts_neg = acts[polarities == -1.0]\n",
    "                labels_affirm = labels[polarities == 1.0]\n",
    "                mean_affirm = torch.mean(acts_affirm, dim=0) \n",
    "                mean_neg = torch.mean(acts_neg, dim=0)\n",
    "                acts_affirm = acts_affirm - mean_affirm\n",
    "                acts_neg = acts_neg - mean_neg\n",
    "                probe = CCSProbe.from_data(acts_affirm, acts_neg, labels_affirm, device=device).to('cpu')\n",
    "            if probe_type == MMProbe:\n",
    "                probe = MMProbe.from_data(acts, labels)\n",
    "\n",
    "            # evaluate classification accuracy on real world scenarios\n",
    "            dm = DataManager()\n",
    "            real_world_dataset = \"real_world_scenarios/all_unambiguous_replies\"\n",
    "            dm.add_dataset(real_world_dataset, model_family, model_size, model_type, layer, split=None, center=False, device='cpu')\n",
    "            acts, labels = dm.data[real_world_dataset]\n",
    "            \n",
    "            # classifier specific predictions\n",
    "            if probe_type == CCSProbe:\n",
    "                acts = acts - (mean_affirm + mean_neg)/2\n",
    "\n",
    "            predictions = probe.pred(acts)\n",
    "            results[probe_type].append((predictions == labels).float().mean().item())\n",
    "            pbar.update(1)\n",
    "\n",
    "for probe_type in probe_types:\n",
    "    mean = np.mean(results[probe_type])\n",
    "    std = np.std(results[probe_type])\n",
    "    print(f\"{probe_type.__name__}:\")\n",
    "    print(f\"  Mean Accuracy: {mean*100:.2f}%\")\n",
    "    print(f\"  Standard Deviation: {std*100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
